#uzun metinlerdeki bağlamları anlamada yardımcı olur kolaylaştırır 
'''
Neden Transformers Kullanılır?
Transformers, doğal dil işleme (NLP) alanında devrim yaratan bir model mimarisidir. Özellikle uzun metinlerdeki bağlamları anlamada ve dil modelleme görevlerinde son derece etkilidir. Transformers, kelimeler arasındaki ilişkileri ve bağlamı dikkate alarak, metinlerin anlamını daha iyi kavrayabilir.
 Bu, dil modelleme, metin sınıflandırma, makine çevirisi ve daha birçok NLP görevinde büyük avantaj sağlar.
 Paralel işlem yetenekleri sayesinde, Transformers büyük veri setlerinde hızlı ve etkili bir şekilde eğitilebilir. Bu, modelin daha geniş bir kelime dağarcığı ve daha karmaşık dil yapıları üzerinde çalışabilmesini sağlar.
 Çeşitli NLP görevlerinde kullanılabilirler ve transfer öğrenme ile önceden eğitilmiş modellerden faydalanarak, belirli görevlerde daha iyi performans gösterebilirler.
 Önceden eğitilmiş modeller, belirli bir görev için ince ayar yapılarak kullanılabilir, bu da eğitim sürecini hızlandırır ve daha az veri ile daha iyi sonuçlar elde edilmesini sağlar.
 Modelleri:
 >BERT (Bidirectional Encoder Representations from Transformers): BERT, metinlerin bağlamını anlamak için çift yönlü bir yaklaşım kullanır. Bu, kelimelerin hem solundan hem de sağından gelen bağlamı dikkate alarak daha iyi bir anlam çıkarır. 
 BERT, metin sınıflandırma, soru cevaplama ve daha birçok NLP görevinde kullanılır.
 >GPT (Generative Pre-trained Transformer): GPT, metin üretimi ve dil modelleme görevlerinde kullanılır.
   Önceden eğitilmiş bir model olarak, belirli bir metin parçasından sonra gelen kelimeleri tahmin edebilir.
   >>Transformers Tabanlı Metin Temsilleri;
   Attention Mekanizması: Transformers, kelimeler arasındaki ilişkileri anlamak için dikkat (attention) mekanizmasını kullanır. Bu, modelin hangi kelimelere odaklanması gerektiğini belirlemesine yardımcı olur.
   Sorgu, Anahtar ve Değer Temsilleri: Transformers, her kelime için sorgu (query), anahtar (key) ve değer (value) temsilleri oluşturur. Bu temsiller, kelimeler arasındaki ilişkileri ve bağlamı anlamak için kullanılır.
   Input Embedding: Metinler, kelime gömme (word embedding) teknikleri kullanılarak sayısal temsillere dönüştürülür. Bu, kelimelerin anlamını ve ilişkilerini sayısal bir biçimde temsil eder.
   Multi-Head Attention: Transformers, birden fazla dikkat başlığı (head) kullanarak kelimeler arasındaki ilişkileri daha iyi anlamaya çalışır. Bu, modelin farklı bağlamları ve ilişkileri aynı anda dikkate almasını sağlar.
 '''